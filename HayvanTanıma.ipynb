{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f13370b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#\"Hayvan Tanıma Git Repostory Oluşturuldu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91a60425",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ufuk/anaconda3/envs/tensor/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/ufuk/anaconda3/envs/tensor/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/ufuk/anaconda3/envs/tensor/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/ufuk/anaconda3/envs/tensor/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/ufuk/anaconda3/envs/tensor/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/ufuk/anaconda3/envs/tensor/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/ufuk/anaconda3/envs/tensor/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/ufuk/anaconda3/envs/tensor/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/ufuk/anaconda3/envs/tensor/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/ufuk/anaconda3/envs/tensor/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/ufuk/anaconda3/envs/tensor/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/ufuk/anaconda3/envs/tensor/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tensorflow.python.keras.optimizers import SGD\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPool2D, Dropout\n",
    "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard, History\n",
    "import tensorflow as tf\n",
    "from time import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"  # UYARILARI KAPATMA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5319 images belonging to 37 classes.\n",
      "Found 1294 images belonging to 37 classes.\n",
      "Found 777 images belonging to 37 classes.\n"
     ]
    }
   ],
   "source": [
    "#print(os.listdir(\"./images/train\"))\n",
    "SIZE = 224\n",
    "EPOCH = 50\n",
    "BATCH = 32\n",
    "train_directory = \"images/train/\"\n",
    "valid_directory = \"images/valid/\"\n",
    "test_directory = \"images/test/\"\n",
    "\n",
    "data_aug = ImageDataGenerator(rotation_range=40,\n",
    "                              width_shift_range=[0.2, 1.0],\n",
    "                              height_shift_range=[0.2, 1.0],\n",
    "                              shear_range=0.2,\n",
    "                              rescale=1. / 255,\n",
    "                              zoom_range=[0.2, 1.0],\n",
    "                              horizontal_flip=True,\n",
    "                              fill_mode=\"nearest\",\n",
    "                              validation_split=0.2,\n",
    "                              vertical_flip=True,\n",
    "                              brightness_range=[0.2, 1.0]\n",
    "                              )\n",
    "test_aug = ImageDataGenerator(rotation_range=40,\n",
    "                              width_shift_range=[0.2, 1.0],\n",
    "                              height_shift_range=[0.2, 1.0],\n",
    "                              shear_range=0.2,\n",
    "                              rescale=1. / 255,\n",
    "                              zoom_range=[0.2, 1.0],\n",
    "                              horizontal_flip=True,\n",
    "                              fill_mode=\"nearest\",\n",
    "                              vertical_flip=True,\n",
    "                              brightness_range=[0.2, 1.0])\n",
    "#Max batch size= available GPU memory bytes / 4 / (size of tensors + trainable parameters)\n",
    "train_generator = data_aug.flow_from_directory(directory=train_directory,\n",
    "                                               batch_size=BATCH,\n",
    "                                               shuffle=True,\n",
    "                                               class_mode=\"categorical\",\n",
    "                                               color_mode=\"rgb\",\n",
    "                                               target_size=(SIZE, SIZE),\n",
    "                                               interpolation=\"nearest\",\n",
    "                                               subset=\"training\",\n",
    "                                               seed=42\n",
    "                                               )\n",
    "validation_generator = data_aug.flow_from_directory(directory=train_directory,\n",
    "                                                    batch_size=BATCH,\n",
    "                                                    shuffle=True,\n",
    "                                                    class_mode=\"categorical\",\n",
    "                                                    color_mode=\"rgb\",\n",
    "                                                    target_size=(SIZE, SIZE),\n",
    "                                                    interpolation=\"nearest\",\n",
    "                                                    subset=\"validation\",\n",
    "                                                    seed=42\n",
    "                                                    )\n",
    "test_generator = test_aug.flow_from_directory(directory=test_directory,\n",
    "                                              batch_size=1,\n",
    "                                              shuffle=False,\n",
    "                                              class_mode=\"categorical\",\n",
    "                                              target_size=(SIZE, SIZE)\n",
    "                                              )\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Abyssinian': 0, 'Bengal': 1, 'Birman': 2, 'Bombay': 3, 'British_Shorthair': 4, 'Egyptian_Mau': 5, 'Maine_Coon': 6, 'Persian': 7, 'Ragdoll': 8, 'Russian_Blue': 9, 'Siamese': 10, 'Sphynx': 11, 'american_bulldog': 12, 'american_pit_bull_terrier': 13, 'basset_hound': 14, 'beagle': 15, 'boxer': 16, 'chihuahua': 17, 'english_cocker_spaniel': 18, 'english_setter': 19, 'german_shorthaired': 20, 'great_pyrenees': 21, 'havanese': 22, 'japanese_chin': 23, 'keeshond': 24, 'leonberger': 25, 'miniature_pinscher': 26, 'newfoundland': 27, 'pomeranian': 28, 'pug': 29, 'saint_bernard': 30, 'samoyed': 31, 'scottish_terrier': 32, 'shiba_inu': 33, 'staffordshire_bull_terrier': 34, 'wheaten_terrier': 35, 'yorkshire_terrier': 36}\n"
     ]
    }
   ],
   "source": [
    "print(train_generator.class_indices)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ufuk/anaconda3/envs/tensor/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Model)                (None, 512)               14714688  \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              525312    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 37)                37925     \n",
      "=================================================================\n",
      "Total params: 15,277,925\n",
      "Trainable params: 563,237\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n",
      "0 input_1 False\n",
      "1 block1_conv1 False\n",
      "2 block1_conv2 False\n",
      "3 block1_pool False\n",
      "4 block2_conv1 False\n",
      "5 block2_conv2 False\n",
      "6 block2_pool False\n",
      "7 block3_conv1 False\n",
      "8 block3_conv2 False\n",
      "9 block3_conv3 False\n",
      "10 block3_pool False\n",
      "11 block4_conv1 False\n",
      "12 block4_conv2 False\n",
      "13 block4_conv3 False\n",
      "14 block4_pool False\n",
      "15 block5_conv1 False\n",
      "16 block5_conv2 False\n",
      "17 block5_conv3 False\n",
      "18 block5_pool False\n",
      "19 global_average_pooling2d False\n"
     ]
    }
   ],
   "source": [
    "\n",
    "vgg16_model = VGG16(pooling=\"avg\", input_shape=(224, 224, 3), weights=\"imagenet\", include_top=False)\n",
    "for layer in vgg16_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "VGG = tf.keras.Sequential([\n",
    "    vgg16_model,\n",
    "    Flatten(),\n",
    "    Dense(units=1024, activation=\"softmax\"),\n",
    "    Dropout(0.5),\n",
    "    Dense(units=37, activation=\"softmax\")\n",
    "])\n",
    "opt = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "VGG.compile(loss=\"categorical_crossentropy\", optimizer=opt,\n",
    "            metrics=[\"acc\"])\n",
    "\n",
    "VGG.summary()\n",
    "for i, layer in enumerate(vgg16_model.layers):\n",
    "    print(i, layer.name, layer.trainable)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166 40\n",
      "Epoch 1/50\n",
      "  2/167 [..............................] - ETA: 10:29 - loss: 3.6115 - acc: 0.0156    "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-02 16:47:16.823427: E tensorflow/core/platform/default/device_tracer.cc:68] CUPTI error: CUPTI_ERROR_INVALID_PARAMETER\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166/167 [============================>.] - ETA: 0s - loss: 3.6122 - acc: 0.0216"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_26062/3388215580.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     21\u001B[0m                       \u001B[0mepochs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mEPOCH\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     22\u001B[0m                       \u001B[0mvalidation_data\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mvalidation_generator\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 23\u001B[0;31m                       \u001B[0mcallbacks\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mvgg16_history_callback\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvgg16_checkpoint\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvgg16_tensorboard\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mearly\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     24\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     25\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/tensor/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001B[0m in \u001B[0;36mfit\u001B[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001B[0m\n\u001B[1;32m    671\u001B[0m           \u001B[0muse_multiprocessing\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0muse_multiprocessing\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    672\u001B[0m           \u001B[0mshuffle\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mshuffle\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 673\u001B[0;31m           initial_epoch=initial_epoch)\n\u001B[0m\u001B[1;32m    674\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mtraining_utils\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mis_eager_dataset_or_iterator\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    675\u001B[0m       \u001B[0;31m# Make sure that y, sample_weights, validation_split are not passed.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/tensor/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001B[0m in \u001B[0;36mfit_generator\u001B[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001B[0m\n\u001B[1;32m   1431\u001B[0m         \u001B[0mshuffle\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mshuffle\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1432\u001B[0m         \u001B[0minitial_epoch\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0minitial_epoch\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1433\u001B[0;31m         steps_name='steps_per_epoch')\n\u001B[0m\u001B[1;32m   1434\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1435\u001B[0m   def evaluate_generator(self,\n",
      "\u001B[0;32m~/anaconda3/envs/tensor/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_generator.py\u001B[0m in \u001B[0;36mmodel_iteration\u001B[0;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\u001B[0m\n\u001B[1;32m    320\u001B[0m           \u001B[0mverbose\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    321\u001B[0m           \u001B[0mmode\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mModeKeys\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mTEST\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 322\u001B[0;31m           steps_name='validation_steps')\n\u001B[0m\u001B[1;32m    323\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    324\u001B[0m       \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mval_results\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlist\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/tensor/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_generator.py\u001B[0m in \u001B[0;36mmodel_iteration\u001B[0;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\u001B[0m\n\u001B[1;32m    262\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    263\u001B[0m       \u001B[0mis_deferred\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_is_compiled\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 264\u001B[0;31m       \u001B[0mbatch_outs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mbatch_function\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0mbatch_data\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    265\u001B[0m       \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mbatch_outs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlist\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    266\u001B[0m         \u001B[0mbatch_outs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mbatch_outs\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/tensor/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001B[0m in \u001B[0;36mtest_on_batch\u001B[0;34m(self, x, y, sample_weight, reset_metrics)\u001B[0m\n\u001B[1;32m   1245\u001B[0m       \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_update_sample_weight_modes\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msample_weights\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0msample_weights\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1246\u001B[0m       \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_make_test_function\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1247\u001B[0;31m       \u001B[0moutputs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtest_function\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# pylint: disable=not-callable\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1248\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1249\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mreset_metrics\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/tensor/lib/python3.7/site-packages/tensorflow/python/keras/backend.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, inputs)\u001B[0m\n\u001B[1;32m   3290\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3291\u001B[0m     fetched = self._callable_fn(*array_vals,\n\u001B[0;32m-> 3292\u001B[0;31m                                 run_metadata=self.run_metadata)\n\u001B[0m\u001B[1;32m   3293\u001B[0m     \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_call_fetch_callbacks\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfetched\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m-\u001B[0m\u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_fetches\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3294\u001B[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001B[0;32m~/anaconda3/envs/tensor/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1456\u001B[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001B[1;32m   1457\u001B[0m                                                \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_handle\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1458\u001B[0;31m                                                run_metadata_ptr)\n\u001B[0m\u001B[1;32m   1459\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mrun_metadata\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1460\u001B[0m           \u001B[0mproto_data\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtf_session\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mTF_GetBuffer\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mrun_metadata_ptr\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "vgg16_filepath = 'vgg_16_' + '-saved-model-{epoch:02d}-acc-{val_acc:.2f}.hdf5'\n",
    "vgg16_checkpoint = ModelCheckpoint(filepath=vgg16_filepath,\n",
    "                                   save_best_only=True,\n",
    "                                   monitor=\"val_acc\",\n",
    "                                   mode=\"max\",\n",
    "                                   verbose=1\n",
    "                                   )\n",
    "early = EarlyStopping(monitor='val_acc', min_delta=0, patience=20, verbose=1, mode='auto')\n",
    "\n",
    "vgg16_tensorboard = TensorBoard(log_dir=\"logs/{}\".format(time()),\n",
    "                                write_graph=True,\n",
    "                                write_images=True,\n",
    "                                histogram_freq=0)\n",
    "vgg16_history_callback = History()\n",
    "\n",
    "Step_size_train = train_generator.n // train_generator.batch_size\n",
    "Step_size_valid = validation_generator.n // validation_generator.batch_size\n",
    "Step_size_test = test_generator.n // test_generator.batch_size\n",
    "print(Step_size_train, Step_size_valid)\n",
    "vgg_history = VGG.fit(train_generator,\n",
    "                      epochs=EPOCH,\n",
    "                      validation_data=validation_generator,\n",
    "                      callbacks=[vgg16_history_callback, vgg16_checkpoint, vgg16_tensorboard, early]\n",
    "\n",
    "\n",
    ")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.plot(vgg16_history_callback.history[\"acc\"])\n",
    "plt.plot(vgg16_history_callback.history['val_acc'])\n",
    "plt.legend(['accuracy', 'validation accuracy'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.plot(vgg16_history_callback.history[\"loss\"])\n",
    "plt.plot(vgg16_history_callback.history['val_loss'])\n",
    "plt.legend(['accuracy', 'validation accuracy'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "score, acc = VGG.evaluate_generator(generator=validation_generator,\n",
    "                                    steps=Step_size_valid)\n",
    "test_generator.reset()\n",
    "\n",
    "pred = VGG.predict_generator(generator=test_generator,\n",
    "                             steps=Step_size_test,\n",
    "                             verbose=1)\n",
    "predicted_class_indces = np.argmax(pred, axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "labels = train_generator.class_indices\n",
    "labels = dict((v, k) for k, v in labels.items())\n",
    "predictions = [labels[k] for k in predicted_class_indces]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "filenames = test_generator.filenames\n",
    "results = pd.DataFrame({\"Filename\": filenames,\n",
    "                        \"Predictions\": predictions})\n",
    "results.to_csv(\"results.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"Test score \", score)\n",
    "print(\"Test acc\", acc)\n",
    "results"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}